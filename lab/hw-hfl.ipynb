{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, ensure you have cloned the [course repository](https://github.com/lydiaYchen/DDL24Spring).\n",
    "\n",
    "Then, open the [interactive notebook version](https://github.com/lydiaYchen/DDL24Spring/blob/main/lab/hw-hfl.ipynb) of this homework from your local clone.\n",
    "\n",
    "Further, complete the homework by filling in the code and answers and save your changes.\n",
    "\n",
    "Finally, upload the notebook to the assignment in ILIAS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When not otherwise specified, use the following parameter values in experiment runs:\n",
    "- `nr_clients` (N): 100\n",
    "- `lr`: 0.01\n",
    "- `client_fraction`(C): 0.1\n",
    "- `nr_local_epochs` (E): 1\n",
    "- `batch_size` (B): 100\n",
    "- `nr_rounds`: 10\n",
    "- `iid`: True\n",
    "\n",
    "For all exercises, pass `seed = 10` to calls for splitting data, server initialization, or plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from base import *\n",
    "\n",
    "n = 100\n",
    "lr = 0.01\n",
    "c = 0.1\n",
    "e = 1\n",
    "b = 100\n",
    "nr_rounds = 10\n",
    "iid = True\n",
    "seed = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 - FedSGD with weights (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(2 points)_ Implement a version of FedSGD that uses weights in its updates, like FedAvg, instead of the gradients from the version of the tutorials. The two FedSGD versions should have the same test accuracy after each round (with a tolerance of at most 0.02%). To show this, compare their output for the following two scenarios over *5 rounds*:\n",
    "- `lr = 0.01, client_subsets = split(100, True, ...), client_fraction = 0.5`\n",
    "- `lr = 0.1, client_subsets = split(50, False, ...), client_fraction = 0.2`\n",
    "\n",
    "*Tip:* You can use the existing FedAvg implementation to minimize the amount of code writing required.\n",
    "\n",
    "_(1 point)_ Explain in which cases (about the different parameters for decentralized learning) the two are equivalent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedSgdWeightServer(DecentralizedServer):\n",
    "    def __init__(\n",
    "            self, lr: float, batch_size: int, client_subsets: list[Subset],\n",
    "            client_fraction: float, nr_local_epochs: int, seed: int) -> None:\n",
    "        super().__init__(lr, batch_size, client_subsets, client_fraction, seed)\n",
    "        self.name = \"FedSgdWeight\"\n",
    "        self.nr_local_epochs = nr_local_epochs\n",
    "        self.optimizer = SGD(params=self.model.parameters(), lr=lr)\n",
    "        self.clients = [\n",
    "            WeightClient(subset, lr, batch_size, nr_local_epochs)\n",
    "            for subset in client_subsets]\n",
    "\n",
    "    def run(self, nr_rounds: int) -> RunResult:\n",
    "        elapsed_time = 0.\n",
    "        run_result = RunResult(self.name, self.nr_clients, self.client_fraction, self.batch_size, self.nr_local_epochs, self.lr, self.seed)\n",
    "\n",
    "        for nr_round in tqdm(range(nr_rounds), desc=\"Rounds\", leave=False):\n",
    "            setup_start_time = perf_counter()\n",
    "            self.model.train()\n",
    "            self.optimizer.zero_grad()\n",
    "            weights = [x.detach().cpu().clone() for x in self.model.parameters()]\n",
    "            indices_chosen_clients = self.rng.choice(self.nr_clients, self.nr_clients_per_round, replace=False)\n",
    "            chosen_sum_nr_samples = sum(self.client_sample_counts[i] for i in indices_chosen_clients)\n",
    "            chosen_adjusted_weights: list[list[torch.Tensor]] = []\n",
    "            elapsed_time += perf_counter() - setup_start_time\n",
    "            update_time = 0.\n",
    "\n",
    "            for c_i in indices_chosen_clients:\n",
    "                update_start_time = perf_counter()\n",
    "                ind = int(c_i)\n",
    "                client_round_seed = self.seed + ind + 1 + nr_round * self.nr_clients_per_round\n",
    "                client_weights = self.clients[ind].update(weights, client_round_seed)\n",
    "                chosen_adjusted_weights.append([\n",
    "                    self.client_sample_counts[ind] / chosen_sum_nr_samples * tens\n",
    "                     for tens in client_weights])\n",
    "                update_time = max(update_time, perf_counter() - update_start_time)\n",
    "\n",
    "            elapsed_time += update_time\n",
    "            aggregate_start_time = perf_counter()\n",
    "            averaged_chosen_weights: list[torch.Tensor] = [sum(x) for x in zip(*chosen_adjusted_weights)]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for client_weight, server_parameter in zip(averaged_chosen_weights, self.model.parameters()):\n",
    "                    server_parameter[:] = client_weight.to(device=device)\n",
    "\n",
    "            self.optimizer.step()\n",
    "            elapsed_time += perf_counter() - aggregate_start_time\n",
    "            run_result.wall_time.append(round(elapsed_time, 1))\n",
    "            run_result.message_count.append(2 * (nr_round + 1) * self.nr_clients_per_round)\n",
    "            run_result.test_accuracy.append(self.test())\n",
    "\n",
    "        return run_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_split = split(100, True, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m fedsgd_weight_server \u001b[38;5;241m=\u001b[39m FedSgdWeightServer(\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m200\u001b[39m, sample_split, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m result_fedsgd_weight \u001b[38;5;241m=\u001b[39m \u001b[43mfedsgd_weight_server\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m fedsgd_weight_df \u001b[38;5;241m=\u001b[39m result_fedsgd_weight\u001b[38;5;241m.\u001b[39mas_df()\n\u001b[1;32m      4\u001b[0m fedsgd_weight_df\n",
      "Cell \u001b[0;32mIn[2], line 50\u001b[0m, in \u001b[0;36mFedSgdWeightServer.run\u001b[0;34m(self, nr_rounds)\u001b[0m\n\u001b[1;32m     48\u001b[0m     run_result\u001b[38;5;241m.\u001b[39mwall_time\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mround\u001b[39m(elapsed_time, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     49\u001b[0m     run_result\u001b[38;5;241m.\u001b[39mmessage_count\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (nr_round \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnr_clients_per_round)\n\u001b[0;32m---> 50\u001b[0m     run_result\u001b[38;5;241m.\u001b[39mtest_accuracy\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m run_result\n",
      "File \u001b[0;32m~/ddls-lab/lab/base.py:172\u001b[0m, in \u001b[0;36mServer.test\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 172\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data, target \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[1;32m    173\u001b[0m         data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(data)\n",
      "File \u001b[0;32m~/ddls-lab/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/ddls-lab/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/ddls-lab/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/ddls-lab/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/ddls-lab/.venv/lib/python3.10/site-packages/torchvision/datasets/mnist.py:138\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, Any]:\n\u001b[1;32m    131\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m        index (int): Index\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m        tuple: (image, target) where target is index of the target class.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m     img, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index], \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# to return a PIL Image\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fedsgd_weight_server = FedSgdWeightServer(0.01, b, sample_split, 0.5, 5, 42)\n",
    "result_fedsgd_weight = fedsgd_weight_server.run(5)\n",
    "fedsgd_weight_df = result_fedsgd_weight.as_df()\n",
    "fedsgd_weight_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Round</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>N</th>\n",
       "      <th>C</th>\n",
       "      <th>B</th>\n",
       "      <th>E</th>\n",
       "      <th>η</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Message count</th>\n",
       "      <th>Test accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>FedSGDGradient</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>∞</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>42</td>\n",
       "      <td>100</td>\n",
       "      <td>8.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>FedSGDGradient</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>∞</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>42</td>\n",
       "      <td>200</td>\n",
       "      <td>9.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>FedSGDGradient</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>∞</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>42</td>\n",
       "      <td>300</td>\n",
       "      <td>9.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>FedSGDGradient</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>∞</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>42</td>\n",
       "      <td>400</td>\n",
       "      <td>9.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>FedSGDGradient</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>∞</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>42</td>\n",
       "      <td>500</td>\n",
       "      <td>9.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Round       Algorithm    N    C  B  E     η  Seed  Message count  \\\n",
       "0      1  FedSGDGradient  100  0.5  ∞  1  0.01    42            100   \n",
       "1      2  FedSGDGradient  100  0.5  ∞  1  0.01    42            200   \n",
       "2      3  FedSGDGradient  100  0.5  ∞  1  0.01    42            300   \n",
       "3      4  FedSGDGradient  100  0.5  ∞  1  0.01    42            400   \n",
       "4      5  FedSGDGradient  100  0.5  ∞  1  0.01    42            500   \n",
       "\n",
       "   Test accuracy  \n",
       "0           8.87  \n",
       "1           9.07  \n",
       "2           9.31  \n",
       "3           9.61  \n",
       "4           9.83  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fedsgd_gradient_server = FedSgdGradientServer(0.01, sample_split, 0.5, 42)\n",
    "result_fedsgd_gradient = fedsgd_gradient_server.run(5)\n",
    "fedsgd_gradient_df = result_fedsgd_gradient.as_df()\n",
    "fedsgd_gradient_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Client number & fraction (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(2 points)_ Run the necessary experiments to fill in the following table showing the final message count and test accuracy of FedSGD and FedAvg for different total client numbers:\n",
    "\n",
    "| Algorithm | N   | C   | Message count | Test accuracy |\n",
    "| --------- | --- | --- | ------------- | ------------- |\n",
    "| FedSGD    | 10  | 0.1 |               |               |\n",
    "| FedAvg    | 10  | 0.1 |               |               |\n",
    "| FedSGD    | 50  | 0.1 |               |               |\n",
    "| FedAvg    | 50  | 0.1 |               |               |\n",
    "| FedSGD    | 100 | 0.1 |               |               |\n",
    "| FedAvg    | 100 | 0.1 |               |               |\n",
    "\n",
    "Is the relationship between the metrics and client numbers monotonous?\n",
    "\n",
    "_(2 points)_ Run the experiments to fill in the table when varying the fraction of clients used in every round:\n",
    "\n",
    "| Algorithm | N   | C    | Message count | Test accuracy |\n",
    "| --------- | --- | ---- | ------------- | ------------- |\n",
    "| FedSGD    | 100 | 0.01 |               |               |\n",
    "| FedAvg    | 100 | 0.01 |               |               |\n",
    "| FedSGD    | 100 | 0.1  |               |               |\n",
    "| FedAvg    | 100 | 0.1  |               |               |\n",
    "| FedSGD    | 100 | 0.2  |               |               |\n",
    "| FedAvg    | 100 | 0.2  |               |               |\n",
    "\n",
    "How does the observed pattern differ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - Batch size & learning rate (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(2 points)_ Complete the following table with the last-round wall time and test accuracy of FedAvg under different batch sizes:\n",
    "\n",
    "| Algorithm | B   | η    | Wall time | Test accuracy |\n",
    "| --------- | --- | ---- | --------- | ------------- |\n",
    "| FedAvg    | 10  | 0.01 |           |               |\n",
    "| FedAvg    | 100 | 0.01 |           |               |\n",
    "| FedAvg    | 500 | 0.01 |           |               |\n",
    "\n",
    "What is the trade-off for larger batch sizes?\n",
    "\n",
    "*Note:* The exact measured time will differ from run to run, even on the same machine, but the trends should remain the same. Furthermore, the effect of batch size on wall time is less pronounced and, depending on the exact hardware is sometimes minimal when running on CPU instead of GPU.\n",
    "\n",
    "_(2 points)_ Add the corresponding values for varying learning rates, also for FedSGD, in the table below:\n",
    "\n",
    "| Algorithm | B   | η     | Wall time | Test accuracy |\n",
    "| --------- | --- | ----- | --------- | ------------- |\n",
    "| FedSGD    | ∞   | 0.001 |           |               |\n",
    "| FedAvg    | 100 | 0.001 |           |               |\n",
    "| FedSGD    | ∞   | 0.01  |           |               |\n",
    "| FedAvg    | 100 | 0.01  |           |               |\n",
    "| FedSGD    | ∞   | 1.0   |           |               |\n",
    "| FedAvg    | 100 | 1.0   |           |               |\n",
    "\n",
    "Does the learning rate influence the wall time? For accuracy, how does it change the value obtained within the set number of rounds? Can it impact the model's convergence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 - Local epoch count & (non-)IID data (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(1 point)_ Create a line plot of the accuracy after each round for the following algorithm variants:\n",
    "\n",
    "- FedSGD\n",
    "- FedAvg (E=1)\n",
    "- FedAvg (E=2)\n",
    "- FedAvg (E=4)\n",
    "\n",
    "How does FedAvg compare to FedSGD? What is the effect of increasing the work clients perform locally for each update in FedAvg?\n",
    "\n",
    "_(2 points)_ Make one line plot of FedSGD and FedAvg under an IID and non-IID split for 15 rounds (leaving all other parameter values as they previously mentioned default). How does the non-IID setting affect the accuracy achieved by the two algorithms? What is the difference in terms of the smoothness of learning?\n",
    "\n",
    "_(2 points)_ Make another plot for only non-IID splits, including the FedSGD and FedAvg configs from before, and add a version for each with a learning rate of 0.001 and client fraction of 0.5. How does the stability of the new variants compare to the old ones? Why do the changes in parameters have the observed effect?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
